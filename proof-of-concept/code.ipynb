{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nolanwelch/ai-factcheck/blob/main/proof-of-concept/code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7qDkj4KH4ns",
        "outputId": "05279137-6e04-4b36-a9ab-9592955227d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-dotenv in /home/nwelch/projects/ai-factcheck/.venv/lib64/python3.13/site-packages (1.0.1)\n",
            "Requirement already satisfied: openai in /home/nwelch/projects/ai-factcheck/.venv/lib64/python3.13/site-packages (1.59.8)\n",
            "Requirement already satisfied: pydantic in /home/nwelch/projects/ai-factcheck/.venv/lib64/python3.13/site-packages (2.10.5)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /home/nwelch/projects/ai-factcheck/.venv/lib64/python3.13/site-packages (from openai) (4.8.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /home/nwelch/projects/ai-factcheck/.venv/lib64/python3.13/site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /home/nwelch/projects/ai-factcheck/.venv/lib64/python3.13/site-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /home/nwelch/projects/ai-factcheck/.venv/lib64/python3.13/site-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /home/nwelch/projects/ai-factcheck/.venv/lib64/python3.13/site-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /home/nwelch/projects/ai-factcheck/.venv/lib64/python3.13/site-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/nwelch/projects/ai-factcheck/.venv/lib64/python3.13/site-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /home/nwelch/projects/ai-factcheck/.venv/lib64/python3.13/site-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /home/nwelch/projects/ai-factcheck/.venv/lib64/python3.13/site-packages (from pydantic) (2.27.2)\n",
            "Requirement already satisfied: idna>=2.8 in /home/nwelch/projects/ai-factcheck/.venv/lib64/python3.13/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /home/nwelch/projects/ai-factcheck/.venv/lib64/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /home/nwelch/projects/ai-factcheck/.venv/lib64/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /home/nwelch/projects/ai-factcheck/.venv/lib64/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install python-dotenv openai pydantic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Qr3iLrzIHyiV"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "IN_COLAB = \"google.colab\" in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "  from google.colab import userdata\n",
        "  openai_token = userdata.get(\"OPENAI_API_KEY\")\n",
        "else:\n",
        "  import os\n",
        "  import dotenv\n",
        "  dotenv.load_dotenv()\n",
        "  openai_token = os.environ.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "assert openai_token is not None, \"Must set the OPENAI_API_KEY environment variable\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mapping=KGMapping(entities={'ent_01': 'Barack Obama', 'ent_02': 'Michelle Obama', 'ent_03': 'Presidency of the United States'}, relations={'rel_01': 'spouseOf', 'rel_02': 'formerOfficeHolder'}) graph=KG(root={'ent_01': {'rel_01': ['ent_02'], 'rel_02': ['ent_03']}, 'ent_02': {'rel_01': ['ent_02']}})\n"
          ]
        }
      ],
      "source": [
        "from typing import Dict, List\n",
        "import json\n",
        "from pydantic import BaseModel, model_validator, RootModel\n",
        "\n",
        "class KGMapping(BaseModel):\n",
        "    entities: Dict[str, str]\n",
        "    relations: Dict[str, str]\n",
        "\n",
        "class KG(RootModel[Dict[str, Dict[str, List[str]]]]):\n",
        "    def __getitem__(self, ent_id: str) -> Dict[str, List[str]]:\n",
        "        return self.root[ent_id]\n",
        "\n",
        "class KnowledgeGraph(BaseModel):\n",
        "    mapping: KGMapping\n",
        "    graph: KG\n",
        "\n",
        "    @model_validator(mode='after')\n",
        "    def _check_references(self) -> \"KnowledgeGraph\":\n",
        "        mapping = self.mapping\n",
        "        graph_dict = self.graph.root\n",
        "\n",
        "        # 1) every source‑entity in graph must exist\n",
        "        for ent_id, rels in graph_dict.items():\n",
        "            if ent_id not in mapping.entities:\n",
        "                raise ValueError(f\"Unknown entity in graph: {ent_id}\")\n",
        "\n",
        "            # 2) every relation must exist\n",
        "            for rel_id, targets in rels.items():\n",
        "                if rel_id not in mapping.relations:\n",
        "                    raise ValueError(f\"Unknown relation in graph: {rel_id}\")\n",
        "\n",
        "                # 3) every target entity must exist\n",
        "                for tgt in targets:\n",
        "                    if tgt not in mapping.entities:\n",
        "                        raise ValueError(f\"Unknown target entity in graph: {tgt}\")\n",
        "\n",
        "        return self\n",
        "\n",
        "def load_knowledge_graph(filepath: str):\n",
        "    with open(filepath) as f:\n",
        "        data = json.load(f)\n",
        "        return KnowledgeGraph.model_validate(data)\n",
        "\n",
        "kg = load_knowledge_graph(\"kg.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "vRhAG8PWKQyU"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import time\n",
        "from dataclasses import dataclass\n",
        "import json\n",
        "\n",
        "# Semantically-grounded IDs\n",
        "entity_ids   = list(kg.mapping.entities.keys())\n",
        "relation_ids = list(kg.mapping.relations.keys())\n",
        "\n",
        "# Human-readable mappings\n",
        "entity_list = \"\\n\".join(f\"- {eid}: {lbl}\" for eid, lbl in kg.mapping.entities.items())\n",
        "relation_list = \"\\n\".join(f\"- {rid}: {lbl}\" for rid, lbl in kg.mapping.relations.items())\n",
        "\n",
        "extract_triples_fn = {\n",
        "    \"name\": \"extract_triples\",\n",
        "    \"description\": f\"\"\"\n",
        "Extract all semantic triples (entityA, relationship, entityB) from a sentence.\n",
        "Use **only** the following IDs:\n",
        "\n",
        "Entities:\n",
        "{entity_list}\n",
        "\n",
        "Relations:\n",
        "{relation_list}\n",
        "\n",
        "Return a JSON object with a single field `triples`, an array of objects:\n",
        "  {{ \"entityA\": <ENTITY_ID>, \"relationship\": <RELATION_ID>, \"entityB\": <ENTITY_ID> }}\n",
        "\n",
        "If there are no triples, return `{{\"triples\":[]}}`.\n",
        "\"\"\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"triples\": {\n",
        "                \"type\": \"array\",\n",
        "                \"items\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"entityA\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"enum\": entity_ids,\n",
        "                            \"description\": \"ID of the first entity\"\n",
        "                        },\n",
        "                        \"relationship\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"enum\": relation_ids,\n",
        "                            \"description\": \"ID of the relationship\"\n",
        "                        },\n",
        "                        \"entityB\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"enum\": entity_ids,\n",
        "                            \"description\": \"ID of the second entity\"\n",
        "                        },\n",
        "                    },\n",
        "                    \"required\": [\"entityA\", \"relationship\", \"entityB\"],\n",
        "                },\n",
        "            },\n",
        "        },\n",
        "        \"required\": [\"triples\"],\n",
        "    },\n",
        "}\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class SemanticTripleExtractor:\n",
        "    client: openai.OpenAI\n",
        "    GPT_MODEL = \"gpt-4o-mini\"\n",
        "    ERROR_RETRY_SLEEP = 0.001\n",
        "\n",
        "    def get_semantic_triples(self, text: str):\n",
        "        system_prompt = \"\"\"\n",
        "            You are a semantic role and entity extractor.  \n",
        "\n",
        "            Given an input sentence, identify every tuple (entityA, relationship, entityB) expressed in that sentence, where:\n",
        "\n",
        "            • entityA and entityB must be one of the entities given in the schema (use the ENTITY IDs)\n",
        "            • relationship must be one of the relations given in the schema (use the RELATION IDs)\n",
        "\n",
        "            Do not invent any new entities or relations.  \n",
        "            Always output **only** valid JSON that matches the provided schema.\n",
        "        \"\"\"\n",
        "        return self._request_with_retry(system_prompt, text)\n",
        "\n",
        "    def _request_with_retry(self, system_prompt: str, text: str):\n",
        "        n_retries = 0\n",
        "        while True:\n",
        "            try:\n",
        "                response = (\n",
        "                    self.client.beta.chat.completions.parse(\n",
        "                        model=self.GPT_MODEL,\n",
        "                        temperature=0,\n",
        "                        messages=[\n",
        "                            {\"role\": \"system\", \"content\": system_prompt},\n",
        "                            {\"role\": \"user\", \"content\": text},\n",
        "                        ],\n",
        "                        functions=[extract_triples_fn],\n",
        "                        function_call={\"name\": \"extract_triples\"},\n",
        "                    )\n",
        "                    .choices[0]\n",
        "                    .message.function_call\n",
        "                )\n",
        "                break\n",
        "\n",
        "            except openai.RateLimitError as err:\n",
        "                n_retries += 1\n",
        "                print(err)\n",
        "                print(\"Exceeded rate limit\")\n",
        "                print(f\"Sleeping before retry (done {n_retries} time(s))\")\n",
        "                time.sleep(self.ERROR_RETRY_SLEEP)\n",
        "\n",
        "            except Exception as err:\n",
        "                n_retries += 1\n",
        "                print(f\"Unexpected error ({err})\")\n",
        "                print(f\"Sleeping before retry (done {n_retries} time(s))\")\n",
        "                time.sleep(self.ERROR_RETRY_SLEEP)\n",
        "\n",
        "        if response is None:\n",
        "            raise ValueError(\"Got null response\")\n",
        "\n",
        "        return json.loads(response.arguments)[\"triples\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "sVfz7tRsWxeM"
      },
      "outputs": [],
      "source": [
        "client = openai.OpenAI(api_key=openai_token)\n",
        "\n",
        "semantic_extractor = SemanticTripleExtractor(client)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jztyxFqaXVYb",
        "outputId": "2a712801-a176-4a06-e7b8-aaf5f2db6cb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Barack Obama formerOfficeHolder Presidency of the United States\n",
            "Barack Obama spouseOf Michelle Obama\n",
            "Michelle Obama spouseOf Barack Obama\n"
          ]
        }
      ],
      "source": [
        "sentence = \"Barack Obama used to be President. \"\n",
        "sentence += \"Thomas Edison invented the lightbulb. \"\n",
        "sentence += \"Barack Obama is married to Michelle Obama, and Michelle Obama is married to Barack Obama.\"\n",
        "\n",
        "triples = semantic_extractor.get_semantic_triples(sentence)\n",
        "\n",
        "# We expect one triple for the first sentence, nothing for the second,\n",
        "#   and two triples for the compound third sentence.\n",
        "for triple in triples:\n",
        "    name_A = kg.mapping.entities[triple[\"entityA\"]]\n",
        "    name_rel = kg.mapping.relations[triple[\"relationship\"]]\n",
        "    name_B = kg.mapping.entities[triple[\"entityB\"]]\n",
        "    print(\" \".join([name_A, name_rel, name_B]))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
