{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nolanwelch/ai-factcheck/blob/main/proof-of-concept/code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install python-dotenv openai pydantic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7qDkj4KH4ns",
        "outputId": "67e2e980-1ea3-4f7b-8c6c-0fc960d34e0f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.0.1)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.59.6)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (2.10.5)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic) (2.27.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Qr3iLrzIHyiV"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "IN_COLAB = \"google.colab\" in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "  from google.colab import userdata\n",
        "  openai_token_present = userdata.get(\"OPENAI_API_KEY\") is not None\n",
        "else:\n",
        "  import os\n",
        "  import dotenv\n",
        "  dotenv.load_dotenv()\n",
        "  openai_token_present = \"HF_TOKEN\" in os.environ\n",
        "\n",
        "assert openai_token_present, \"Must set the OPENAI_API_KEY environment variable\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel\n",
        "from enum import Enum\n",
        "\n",
        "class SemanticTriple(BaseModel):\n",
        "  entityA: str\n",
        "  relationship: str\n",
        "  entityB: str\n",
        "\n",
        "class SemanticTripleList(BaseModel):\n",
        "  triples: list[SemanticTriple]\n",
        "\n",
        "class EntailmentRelationship(Enum):\n",
        "  IMPLIES = \"implies\"\n",
        "  CONTRADICTS = \"contradicts\"\n",
        "  NEUTRAL = \"neutral\"\n",
        "\n",
        "class EntailmentResponse(BaseModel):\n",
        "  entailment_relationship: EntailmentRelationship"
      ],
      "metadata": {
        "id": "vRhAG8PWKQyU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from dataclasses import dataclass\n",
        "import time\n",
        "\n",
        "@dataclass\n",
        "class SemanticTripleExtractor:\n",
        "  client: openai.OpenAI\n",
        "  GPT_MODEL = \"gpt-4o\"\n",
        "  SCHEMA = SemanticTripleList\n",
        "\n",
        "  def get_semantic_triples(self, text: str):\n",
        "    system_prompt = \"\"\"\n",
        "    You are an advanced natural language processing model tasked with extracting semantic triples from text. A semantic triple is a structured representation of knowledge in the form of **(subject, predicate, object)**. Your goal is to parse the text and extract meaningful triples that encapsulate the relationships and facts described.\n",
        "\n",
        "    ### Instructions:\n",
        "    1. **Core Structure**:\n",
        "      - Each triple should be in the format: **(entityA, predicate, entityB)**.\n",
        "      - **entityA** is the entity or concept performing or being described by the action or state.\n",
        "      - The **predicate** is the verb or relational term connecting the subject and the object.\n",
        "      - **entityB** is the entity or concept associated with entityA via the predicate.\n",
        "\n",
        "    2. **Negated Triples**:\n",
        "      - For any statement involving negation (e.g., \"not,\" \"never\"), extract the triple as if the negation were absent.\n",
        "      - Example:\n",
        "        - Input: \"Alexander the Great was not British.\"\n",
        "        - Output: **(Alexander the Great, was, British)**.\n",
        "\n",
        "    3. **Handling Ambiguity**:\n",
        "      - Disambiguate unclear or indirect references to identify explicit triples.\n",
        "      - If coreference resolution is needed (e.g., pronouns), resolve the references first.\n",
        "      - Example:\n",
        "        - Input: \"He never became a king.\"\n",
        "        - Output: **(He, became, king)**.\n",
        "\n",
        "    4. **Complex Sentences**:\n",
        "      - For compound or complex sentences, extract all relevant triples.\n",
        "      - Example:\n",
        "        - Input: \"Albert Einstein was a physicist and did not believe in quantum entanglement.\"\n",
        "        - Output: **(Albert Einstein, was, physicist)**, **(Albert Einstein, believed, quantum entanglement)**.\n",
        "\n",
        "    5. **Contextual Relationships**:\n",
        "      - Use contextual clues to infer relationships when not explicitly stated.\n",
        "      - Example:\n",
        "        - Input: \"The Eiffel Tower is in Paris.\"\n",
        "        - Output: **(The Eiffel Tower, is in, Paris)**.\n",
        "\n",
        "    6. **Specificity**:\n",
        "      - Extract triples with the highest level of specificity based on the input text.\n",
        "      - Example:\n",
        "        - Input: \"The company Tesla manufactures electric cars.\"\n",
        "        - Output: **(Tesla, manufactures, electric cars)**.\n",
        "\n",
        "    7. **Language Precision**:\n",
        "      - Maintain the integrity of the original text's meaning, but omit any hedging language or modifiers unless crucial to understanding.\n",
        "      - Example:\n",
        "        - Input: \"It is widely believed that cats are nocturnal.\"\n",
        "        - Output: **(cats, are, nocturnal)**.\n",
        "\n",
        "    8. **Output Format**:\n",
        "      - Return triples in plain text, separated by commas, and encapsulated in parentheses.\n",
        "      - Multiple triples should be separated by line breaks.\n",
        "\n",
        "    ### Examples for Clarity:\n",
        "    #### Example 1:\n",
        "    - **Input**: \"The Great Wall of China is not visible from space.\"\n",
        "    - **Output**:\n",
        "      - **(The Great Wall of China, is visible from, space)**\n",
        "\n",
        "    #### Example 2:\n",
        "    - **Input**: \"Marie Curie discovered radium and polonium but did not work on the atomic bomb.\"\n",
        "    - **Output**:\n",
        "      - **(Marie Curie, discovered, radium)**\n",
        "      - **(Marie Curie, discovered, polonium)**\n",
        "      - **(Marie Curie, worked on, the atomic bomb)**\n",
        "\n",
        "    #### Example 3:\n",
        "    - **Input**: \"He was not interested in sports and did not enjoy reading novels.\"\n",
        "    - **Output**:\n",
        "      - **(He, was interested in, sports)**\n",
        "      - **(He, enjoyed, reading novels)**\n",
        "\n",
        "    #### Example 4:\n",
        "    - **Input**: \"Although Paris is not the capital of Germany, it is known for its culture.\"\n",
        "    - **Output**:\n",
        "      - **(Paris, is the capital of, Germany)**\n",
        "      - **(Paris, is known for, culture)**\n",
        "\n",
        "    ### Constraints:\n",
        "    - Do not include duplicate triples.\n",
        "    - Ensure grammatical consistency in predicates.\n",
        "    - Focus on relationships that are explicitly stated or strongly implied.\n",
        "\n",
        "    With these guidelines, extract accurate and meaningful semantic triples from any input text provided.\"\"\"\n",
        "    return self._request_with_retry(system_prompt, text)\n",
        "\n",
        "    def _request_with_retry(self, system_prompt: str, text: str):\n",
        "      n_retries = 0\n",
        "      while True:\n",
        "          try:\n",
        "              response = (\n",
        "                  self._client.beta.chat.completions.parse(\n",
        "                      model=self.model.value,\n",
        "                      response_format=self.SCHEMA,\n",
        "                      messages=[\n",
        "                          {\"role\": \"system\", \"content\": system_prompt},\n",
        "                          {\"role\": \"user\", \"content\": text},\n",
        "                      ],\n",
        "                  )\n",
        "                  .choices[0]\n",
        "                  .message.parsed\n",
        "              )\n",
        "              break\n",
        "\n",
        "          except openai.RateLimitError as err:\n",
        "              n_retries += 1\n",
        "              print(err)\n",
        "              print(\"Exceeded rate limit\")\n",
        "              print(f\"Sleeping before retry (done {n_retries} time(s))\")\n",
        "              time.sleep(self.ERROR_RETRY_SLEEP)\n",
        "\n",
        "          except Exception as err:\n",
        "              n_retries += 1\n",
        "              print(f\"Unexpected error ({err})\")\n",
        "              print(f\"Sleeping before retry (done {n_retries} time(s))\")\n",
        "              time.sleep(self.ERROR_RETRY_SLEEP)\n"
      ],
      "metadata": {
        "id": "san_1NMbM-70"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}