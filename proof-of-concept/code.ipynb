{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nolanwelch/ai-factcheck/blob/main/proof-of-concept/code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install python-dotenv openai pydantic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7qDkj4KH4ns",
        "outputId": "67e2e980-1ea3-4f7b-8c6c-0fc960d34e0f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.0.1)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.59.6)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (2.10.5)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic) (2.27.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Qr3iLrzIHyiV"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "IN_COLAB = \"google.colab\" in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "  from google.colab import userdata\n",
        "  openai_token = userdata.get(\"OPENAI_API_KEY\")\n",
        "else:\n",
        "  import os\n",
        "  import dotenv\n",
        "  dotenv.load_dotenv()\n",
        "  openai_token = os.environ.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "assert openai_token is not None, \"Must set the OPENAI_API_KEY environment variable\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel\n",
        "from enum import Enum\n",
        "\n",
        "class SemanticTriple(BaseModel):\n",
        "  entityA: str\n",
        "  relationship: str\n",
        "  entityB: str\n",
        "\n",
        "class SemanticTripleList(BaseModel):\n",
        "  triples: list[SemanticTriple]\n",
        "\n",
        "class EntailmentRelationship(Enum):\n",
        "  IMPLIES = \"implies\"\n",
        "  CONTRADICTS = \"contradicts\"\n",
        "  NEUTRAL = \"neutral\"\n",
        "\n",
        "class EntailmentResponse(BaseModel):\n",
        "  entailment_relationship: EntailmentRelationship"
      ],
      "metadata": {
        "id": "vRhAG8PWKQyU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from dataclasses import dataclass\n",
        "import time\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class SemanticTripleExtractor:\n",
        "    client: openai.OpenAI\n",
        "    GPT_MODEL = \"gpt-4o\"\n",
        "    SCHEMA = SemanticTripleList\n",
        "    ERROR_RETRY_SLEEP = 0.001\n",
        "\n",
        "    def get_semantic_triples(self, text: str):\n",
        "        system_prompt = \"\"\"\n",
        "    You are an advanced natural language processing model tasked with extracting semantic triples from text. A semantic triple is a structured representation of knowledge in the form of **(subject, predicate, object)**. Your goal is to parse the text and extract meaningful triples that encapsulate the relationships and facts described.\n",
        "\n",
        "    ### Instructions:\n",
        "    1. **Core Structure**:\n",
        "      - Each triple should be in the format: **(entityA, predicate, entityB)**.\n",
        "      - **entityA** is the entity or concept performing or being described by the action or state.\n",
        "      - The **predicate** is the verb or relational term connecting the subject and the object.\n",
        "      - **entityB** is the entity or concept associated with entityA via the predicate.\n",
        "\n",
        "    2. **Negated Triples**:\n",
        "      - For any statement involving negation (e.g., \"not,\" \"never\"), extract the triple as if the negation were absent.\n",
        "      - Example:\n",
        "        - Input: \"Alexander the Great was not British.\"\n",
        "        - Output: **(Alexander the Great, was, British)**.\n",
        "\n",
        "    3. **Handling Ambiguity**:\n",
        "      - Disambiguate unclear or indirect references to identify explicit triples.\n",
        "      - If coreference resolution is needed (e.g., pronouns), resolve the references first.\n",
        "      - Example:\n",
        "        - Input: \"He never became a king.\"\n",
        "        - Output: **(He, became, king)**.\n",
        "\n",
        "    4. **Complex Sentences**:\n",
        "      - For compound or complex sentences, extract all relevant triples.\n",
        "      - Example:\n",
        "        - Input: \"Albert Einstein was a physicist and did not believe in quantum entanglement.\"\n",
        "        - Output: **(Albert Einstein, was, physicist)**, **(Albert Einstein, believed, quantum entanglement)**.\n",
        "\n",
        "    5. **Contextual Relationships**:\n",
        "      - Use contextual clues to infer relationships when not explicitly stated.\n",
        "      - Example:\n",
        "        - Input: \"The Eiffel Tower is in Paris.\"\n",
        "        - Output: **(The Eiffel Tower, is in, Paris)**.\n",
        "\n",
        "    6. **Specificity**:\n",
        "      - Extract triples with the highest level of specificity based on the input text.\n",
        "      - Example:\n",
        "        - Input: \"The company Tesla manufactures electric cars.\"\n",
        "        - Output: **(Tesla, manufactures, electric cars)**.\n",
        "\n",
        "    7. **Language Precision**:\n",
        "      - Maintain the integrity of the original text's meaning, but omit any hedging language or modifiers unless crucial to understanding.\n",
        "      - Example:\n",
        "        - Input: \"It is widely believed that cats are nocturnal.\"\n",
        "        - Output: **(cats, are, nocturnal)**.\n",
        "\n",
        "    8. **Output Format**:\n",
        "      - Return triples in plain text, separated by commas, and encapsulated in parentheses.\n",
        "      - Multiple triples should be separated by line breaks.\n",
        "\n",
        "    ### Examples for Clarity:\n",
        "    #### Example 1:\n",
        "    - **Input**: \"The Great Wall of China is not visible from space.\"\n",
        "    - **Output**:\n",
        "      - **(The Great Wall of China, is visible from, space)**\n",
        "\n",
        "    #### Example 2:\n",
        "    - **Input**: \"Marie Curie discovered radium and polonium but did not work on the atomic bomb.\"\n",
        "    - **Output**:\n",
        "      - **(Marie Curie, discovered, radium)**\n",
        "      - **(Marie Curie, discovered, polonium)**\n",
        "      - **(Marie Curie, worked on, the atomic bomb)**\n",
        "\n",
        "    #### Example 3:\n",
        "    - **Input**: \"He was not interested in sports and did not enjoy reading novels.\"\n",
        "    - **Output**:\n",
        "      - **(He, was interested in, sports)**\n",
        "      - **(He, enjoyed, reading novels)**\n",
        "\n",
        "    #### Example 4:\n",
        "    - **Input**: \"Although Paris is not the capital of Germany, it is known for its culture.\"\n",
        "    - **Output**:\n",
        "      - **(Paris, is the capital of, Germany)**\n",
        "      - **(Paris, is known for, culture)**\n",
        "\n",
        "    ### Constraints:\n",
        "    - Do not include duplicate triples.\n",
        "    - Ensure grammatical consistency in predicates.\n",
        "    - Focus on relationships that are explicitly stated or strongly implied.\n",
        "\n",
        "    With these guidelines, extract accurate and meaningful semantic triples from any input text provided.\"\"\"\n",
        "        return self._request_with_retry(system_prompt, text)\n",
        "\n",
        "    def _request_with_retry(self, system_prompt: str, text: str):\n",
        "        n_retries = 0\n",
        "        while True:\n",
        "            try:\n",
        "                response = (\n",
        "                    self.client.beta.chat.completions.parse(\n",
        "                        model=self.GPT_MODEL,\n",
        "                        response_format=self.SCHEMA,\n",
        "                        messages=[\n",
        "                            {\"role\": \"system\", \"content\": system_prompt},\n",
        "                            {\"role\": \"user\", \"content\": text},\n",
        "                        ],\n",
        "                    )\n",
        "                    .choices[0]\n",
        "                    .message.parsed\n",
        "                )\n",
        "                break\n",
        "\n",
        "            except openai.RateLimitError as err:\n",
        "                n_retries += 1\n",
        "                print(err)\n",
        "                print(\"Exceeded rate limit\")\n",
        "                print(f\"Sleeping before retry (done {n_retries} time(s))\")\n",
        "                time.sleep(self.ERROR_RETRY_SLEEP)\n",
        "\n",
        "            except Exception as err:\n",
        "                n_retries += 1\n",
        "                print(f\"Unexpected error ({err})\")\n",
        "                print(f\"Sleeping before retry (done {n_retries} time(s))\")\n",
        "                time.sleep(self.ERROR_RETRY_SLEEP)\n",
        "\n",
        "        if response is None:\n",
        "            raise ValueError(\"Got null response\")\n",
        "\n",
        "        return response\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class EntailmentClassifier:\n",
        "    client: openai.OpenAI\n",
        "    GPT_MODEL = \"gpt-4o\"\n",
        "    SCHEMA = EntailmentResponse\n",
        "    ERROR_RETRY_SLEEP = 0.001\n",
        "\n",
        "    def get_entailment_type(self, sentence: str, statement: str):\n",
        "        system_prompt = \"\"\"\n",
        "    You are a highly capable natural language processing model tasked with evaluating the relationship between a given **sentence** and an **assertion**. Your objective is to determine whether the sentence:\n",
        "\n",
        "    1. **Agrees with (Implies)** the assertion: The sentence provides evidence that the assertion is true.\n",
        "    2. **Contradicts** the assertion: The sentence provides evidence that the assertion is false.\n",
        "    3. **Is Neutral** towards the assertion: The sentence neither supports nor refutes the assertion, or it lacks sufficient information to establish a clear relationship.\n",
        "\n",
        "    ### Instructions:\n",
        "\n",
        "    1. **Input Format**:\n",
        "      - You will receive two inputs:\n",
        "        - **Sentence**: A statement or set of statements that describe an event, opinion, or fact.\n",
        "        - **Assertion**: A single statement whose relationship to the sentence you must evaluate.\n",
        "\n",
        "    2. **Output Format**:\n",
        "      - Your response should contain one of the following three terms:\n",
        "        - **\"Implies\"**: If the sentence provides direct or strong evidence supporting the truth of the assertion.\n",
        "        - **\"Contradicts\"**: If the sentence provides direct or strong evidence opposing the truth of the assertion.\n",
        "        - **\"Neutral\"**: If the sentence does not provide sufficient evidence to determine the truth or falsity of the assertion.\n",
        "\n",
        "      - Additionally, provide a brief justification explaining your reasoning.\n",
        "\n",
        "    3. **Evaluation Criteria**:\n",
        "      - **Agreement (Implies)**:\n",
        "        - Identify whether the sentence affirms or supports the assertion.\n",
        "        - Example:\n",
        "          - Sentence: \"I like dogs. I would like to have one some day.\"\n",
        "          - Assertion: \"I like dogs.\"\n",
        "          - Output: **\"Implies\"** (The sentence explicitly states liking dogs.)\n",
        "\n",
        "      - **Contradiction**:\n",
        "        - Determine if the sentence negates or opposes the assertion.\n",
        "        - Example:\n",
        "          - Sentence: \"I don't like dogs. They make me nervous.\"\n",
        "          - Assertion: \"I like dogs.\"\n",
        "          - Output: **\"Contradicts\"** (The sentence explicitly denies liking dogs.)\n",
        "\n",
        "      - **Neutrality**:\n",
        "        - Assess whether the sentence is unrelated to the assertion or lacks sufficient evidence to establish a relationship.\n",
        "        - Example:\n",
        "          - Sentence: \"I like dogs. I would like to have one some day.\"\n",
        "          - Assertion: \"I like cats.\"\n",
        "          - Output: **\"Neutral\"** (The sentence does not provide information about cats.)\n",
        "\n",
        "    4. **Context Awareness**:\n",
        "      - Consider the context and nuances of both the sentence and assertion.\n",
        "      - Handle implied meanings, indirect statements, and logical implications.\n",
        "      - Example:\n",
        "        - Sentence: \"I love all kinds of animals, especially dogs.\"\n",
        "        - Assertion: \"I like dogs.\"\n",
        "        - Output: **\"Implies\"** (The statement includes liking dogs as part of loving animals.)\n",
        "\n",
        "    5. **Ambiguity**:\n",
        "      - If the relationship between the sentence and assertion is ambiguous, select \"Neutral\" and explain why the connection is unclear or insufficient.\n",
        "\n",
        "    6. **Complex Sentences**:\n",
        "      - For compound or complex sentences, focus on the part(s) relevant to the assertion.\n",
        "      - Example:\n",
        "        - Sentence: \"I like dogs, but I don't like walking them in the rain.\"\n",
        "        - Assertion: \"I like dogs.\"\n",
        "        - Output: **\"Implies\"** (The sentence explicitly states liking dogs, even if it mentions a dislike of walking them in certain conditions.)\n",
        "\n",
        "    7. **Negations and Opposites**:\n",
        "      - Pay special attention to negations, double negatives, and antonyms.\n",
        "      - Example:\n",
        "        - Sentence: \"I would never say I dislike dogs.\"\n",
        "        - Assertion: \"I like dogs.\"\n",
        "        - Output: **\"Implies\"** (The sentence indirectly supports the assertion by rejecting the opposite.)\n",
        "\n",
        "    ### Examples:\n",
        "\n",
        "    #### Example 1:\n",
        "    - **Sentence**: \"I absolutely love spending time with dogs.\"\n",
        "    - **Assertion**: \"I like dogs.\"\n",
        "    - **Output**: **\"Implies\"** (The sentence strongly supports the assertion.)\n",
        "\n",
        "    #### Example 2:\n",
        "    - **Sentence**: \"I prefer cats over dogs.\"\n",
        "    - **Assertion**: \"I like dogs.\"\n",
        "    - **Output**: **\"Neutral\"** (The sentence does not confirm or deny liking dogs, only that cats are preferred.)\n",
        "\n",
        "    #### Example 3:\n",
        "    - **Sentence**: \"I don't like dogs because they bark too much.\"\n",
        "    - **Assertion**: \"I like dogs.\"\n",
        "    - **Output**: **\"Contradicts\"** (The sentence directly denies liking dogs.)\n",
        "\n",
        "    #### Example 4:\n",
        "    - **Sentence**: \"I think dogs are cute, but I wouldn't want one as a pet.\"\n",
        "    - **Assertion**: \"I like dogs.\"\n",
        "    - **Output**: **\"Neutral\"** (The sentence expresses admiration for dogs but does not explicitly indicate liking them.)\n",
        "\n",
        "    ### Constraints:\n",
        "    - Focus on the logical relationship between the sentence and the assertion, rather than external knowledge.\n",
        "    - Avoid over-interpreting vague or ambiguous statements; err on the side of neutrality when in doubt.\n",
        "\n",
        "    With these instructions, evaluate each input pair thoroughly and consistently.\"\"\"\n",
        "        text = f\"Sentence: \\\"{sentence}\\\"\\nAssertion: \\\"{statement}\\\"\"\n",
        "        return self._request_with_retry(system_prompt, text)\n",
        "\n",
        "    def _request_with_retry(self, system_prompt: str, text: str):\n",
        "        n_retries = 0\n",
        "        while True:\n",
        "            try:\n",
        "                response = (\n",
        "                    self.client.beta.chat.completions.parse(\n",
        "                        model=self.GPT_MODEL,\n",
        "                        response_format=self.SCHEMA,\n",
        "                        messages=[\n",
        "                            {\"role\": \"system\", \"content\": system_prompt},\n",
        "                            {\"role\": \"user\", \"content\": text},\n",
        "                        ],\n",
        "                    )\n",
        "                    .choices[0]\n",
        "                    .message.parsed\n",
        "                )\n",
        "                break\n",
        "\n",
        "            except openai.RateLimitError as err:\n",
        "                n_retries += 1\n",
        "                print(err)\n",
        "                print(\"Exceeded rate limit\")\n",
        "                print(f\"Sleeping before retry (done {n_retries} time(s))\")\n",
        "                time.sleep(self.ERROR_RETRY_SLEEP)\n",
        "\n",
        "            except Exception as err:\n",
        "                n_retries += 1\n",
        "                print(f\"Unexpected error ({err})\")\n",
        "                print(f\"Sleeping before retry (done {n_retries} time(s))\")\n",
        "                time.sleep(self.ERROR_RETRY_SLEEP)\n",
        "\n",
        "        if response is None:\n",
        "            raise ValueError(\"Got null response\")\n",
        "\n",
        "        return response\n"
      ],
      "metadata": {
        "id": "san_1NMbM-70"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = openai.OpenAI(api_key=openai_token)\n",
        "\n",
        "semantic_extractor = SemanticTripleExtractor(client)\n",
        "entailment_classifier = EntailmentClassifier(client)"
      ],
      "metadata": {
        "id": "sVfz7tRsWxeM"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"Thomas Edison was the inventor of the lightbulb.\"\n",
        "\n",
        "semantic_extractor.get_semantic_triples(sentence)"
      ],
      "metadata": {
        "id": "jztyxFqaXVYb",
        "outputId": "a6937a32-8dc5-44ac-b1f4-c3365a71250c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SemanticTripleList(triples=[SemanticTriple(entityA='Thomas Edison', relationship='was the inventor of', entityB='the lightbulb')])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "true_statement = \"The lightbulb has been invented.\"\n",
        "entailment_classifier.get_entailment_type(sentence, true_statement)"
      ],
      "metadata": {
        "id": "CeIxuxakY4ox",
        "outputId": "9c762d0f-4c82-4019-c004-5ef41ba9ac42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EntailmentResponse(entailment_relationship=<EntailmentRelationship.IMPLIES: 'implies'>)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "false_statement = \"Harry Truman invented the lightbulb.\"\n",
        "entailment_classifier.get_entailment_type(sentence, false_statement)"
      ],
      "metadata": {
        "id": "tg5MuahoZYLP",
        "outputId": "40b15f2c-3675-4a36-b4ca-93300f3eda74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EntailmentResponse(entailment_relationship=<EntailmentRelationship.CONTRADICTS: 'contradicts'>)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "irrelevant_statement = \"I had a sandwich for lunch.\"\n",
        "entailment_classifier.get_entailment_type(sentence, irrelevant_statement)"
      ],
      "metadata": {
        "id": "0b5M3RX-ZY4P",
        "outputId": "91afc31c-bff2-4391-afd1-2941e7e13e08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EntailmentResponse(entailment_relationship=<EntailmentRelationship.NEUTRAL: 'neutral'>)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}